{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data Ingestion, MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a2302cdd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Data Exploration\n",
    "% matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "image = mnist.test.images[1].reshape([28,28])\n",
    "plt.imshow(image)\n",
    "label = mnist.test.labels[1]\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The test data volume 10000\n",
      "The train data volume 55000\n"
     ]
    }
   ],
   "source": [
    "# len of training and testing data\n",
    "print(\"The test data volume\", len(mnist.test.images))\n",
    "print(\"The train data volume\", len(mnist.train.images))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing 10000\n",
      "Training 55000\n"
     ]
    }
   ],
   "source": [
    "# len of labels \n",
    "print(\"Testing\", len(mnist.test.labels))\n",
    "print(\"Training\", len(mnist.train.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.00001\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    \n",
    "    # TODO : Layer 1 - 28*28*1 to 14*14*32 \n",
    "    #conv1\n",
    "    cLayer1 = conv2d(x, weights['wc1'],biases['bc1'])\n",
    "    #maxpool\n",
    "    mPool1 = maxpool2d(cLayer1)\n",
    "    \n",
    "    # TODO: Layer 2 - 14*14*32 to 7*7*64\n",
    "    #conv2\n",
    "    cLayer2 = conv2d(mPool1, weights['wc2'], biases['bc2'])\n",
    "    #maxpool\n",
    "    mPool2 = maxpool2d(cLayer2)\n",
    "\n",
    "    # TODO: Fully connected layer - 7*7*64 to 1024\n",
    "    #reshape\n",
    "    fcLayerIn = tf.reshape(mPool2, [-1, 7*7*64])\n",
    "    #multiply and add bias\n",
    "    mulBias = tf.matmul(fcLayerIn, weights['wd1'])\n",
    "    mulAddBias = tf.add(mulBias, biases['bd1'])\n",
    "    # relu activation\n",
    "    fc1 = tf.nn.relu(mulAddBias)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 - Loss: 54321.3906 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch   2 - Loss: 37562.1484 Validation Accuracy: 0.101562\n",
      "Epoch  1, Batch   3 - Loss: 40403.0547 Validation Accuracy: 0.085938\n",
      "Epoch  1, Batch   4 - Loss: 31077.9531 Validation Accuracy: 0.093750\n",
      "Epoch  1, Batch   5 - Loss: 36356.6797 Validation Accuracy: 0.074219\n",
      "Epoch  1, Batch   6 - Loss: 31354.2695 Validation Accuracy: 0.082031\n",
      "Epoch  1, Batch   7 - Loss: 30470.3887 Validation Accuracy: 0.078125\n",
      "Epoch  1, Batch   8 - Loss: 26077.6191 Validation Accuracy: 0.078125\n",
      "Epoch  1, Batch   9 - Loss: 30317.3262 Validation Accuracy: 0.078125\n",
      "Epoch  1, Batch  10 - Loss: 30333.3711 Validation Accuracy: 0.089844\n",
      "Epoch  1, Batch  11 - Loss: 29707.4473 Validation Accuracy: 0.097656\n",
      "Epoch  1, Batch  12 - Loss: 26271.0371 Validation Accuracy: 0.089844\n",
      "Epoch  1, Batch  13 - Loss: 29003.5781 Validation Accuracy: 0.097656\n",
      "Epoch  1, Batch  14 - Loss: 21567.2422 Validation Accuracy: 0.105469\n",
      "Epoch  1, Batch  15 - Loss: 23172.6055 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch  16 - Loss: 25312.3867 Validation Accuracy: 0.128906\n",
      "Epoch  1, Batch  17 - Loss: 24459.9492 Validation Accuracy: 0.148438\n",
      "Epoch  1, Batch  18 - Loss: 24451.9844 Validation Accuracy: 0.160156\n",
      "Epoch  1, Batch  19 - Loss: 20074.7930 Validation Accuracy: 0.175781\n",
      "Epoch  1, Batch  20 - Loss: 22254.7656 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch  21 - Loss: 23099.5254 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  22 - Loss: 19365.9180 Validation Accuracy: 0.171875\n",
      "Epoch  1, Batch  23 - Loss: 17181.2031 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  24 - Loss: 17511.6953 Validation Accuracy: 0.195312\n",
      "Epoch  1, Batch  25 - Loss: 18091.8828 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  26 - Loss: 19000.7461 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  27 - Loss: 17658.5762 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  28 - Loss: 18293.2559 Validation Accuracy: 0.230469\n",
      "Epoch  1, Batch  29 - Loss: 15897.4414 Validation Accuracy: 0.234375\n",
      "Epoch  1, Batch  30 - Loss: 19245.4961 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  31 - Loss: 15929.7246 Validation Accuracy: 0.246094\n",
      "Epoch  1, Batch  32 - Loss: 16708.2949 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  33 - Loss: 14965.2891 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  34 - Loss: 15522.3018 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  35 - Loss: 15382.5381 Validation Accuracy: 0.269531\n",
      "Epoch  1, Batch  36 - Loss: 14511.2812 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  37 - Loss: 15877.6104 Validation Accuracy: 0.281250\n",
      "Epoch  1, Batch  38 - Loss: 14074.8242 Validation Accuracy: 0.277344\n",
      "Epoch  1, Batch  39 - Loss: 14607.7520 Validation Accuracy: 0.289062\n",
      "Epoch  1, Batch  40 - Loss: 14066.6064 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  41 - Loss: 13590.3574 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  42 - Loss: 15356.2871 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  43 - Loss: 12551.3906 Validation Accuracy: 0.292969\n",
      "Epoch  1, Batch  44 - Loss: 13603.8213 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  45 - Loss: 13721.1201 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  46 - Loss: 11372.6699 Validation Accuracy: 0.316406\n",
      "Epoch  1, Batch  47 - Loss: 12396.7812 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  48 - Loss: 11532.2090 Validation Accuracy: 0.320312\n",
      "Epoch  1, Batch  49 - Loss: 12695.8740 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  50 - Loss:  9899.7598 Validation Accuracy: 0.328125\n",
      "Epoch  1, Batch  51 - Loss:  9348.5137 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  52 - Loss: 11117.4512 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  53 - Loss:  9611.8105 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  54 - Loss:  9803.6348 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  55 - Loss: 11305.6270 Validation Accuracy: 0.343750\n",
      "Epoch  1, Batch  56 - Loss: 10557.3848 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  57 - Loss:  8802.3496 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  58 - Loss: 10668.6631 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  59 - Loss:  9810.7637 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  60 - Loss: 11571.6328 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  61 - Loss:  9700.4199 Validation Accuracy: 0.355469\n",
      "Epoch  1, Batch  62 - Loss:  8408.2158 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  63 - Loss: 10058.3984 Validation Accuracy: 0.347656\n",
      "Epoch  1, Batch  64 - Loss:  9487.1680 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  65 - Loss:  9713.1650 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  66 - Loss:  8562.2207 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  67 - Loss:  9014.4141 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  68 - Loss:  6669.2832 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  69 - Loss:  8724.1191 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  70 - Loss:  7511.8237 Validation Accuracy: 0.363281\n",
      "Epoch  1, Batch  71 - Loss:  8081.3848 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  72 - Loss:  7262.6602 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  73 - Loss:  7910.9888 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  74 - Loss:  8088.5884 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  75 - Loss:  8812.8213 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  76 - Loss:  7270.5547 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  77 - Loss:  9018.7744 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  78 - Loss:  8286.9766 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  79 - Loss:  5885.4272 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  80 - Loss:  7418.7480 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  81 - Loss:  7272.8584 Validation Accuracy: 0.425781\n",
      "Epoch  1, Batch  82 - Loss:  7652.8008 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  83 - Loss:  6733.0073 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  84 - Loss:  6800.6387 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  85 - Loss:  6077.5557 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  86 - Loss:  6897.3789 Validation Accuracy: 0.464844\n",
      "Epoch  1, Batch  87 - Loss:  6078.7520 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  88 - Loss:  6623.4492 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  89 - Loss:  6117.9336 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  90 - Loss:  7442.0513 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  91 - Loss:  7117.5410 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  92 - Loss:  8325.1172 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  93 - Loss:  6098.0752 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  94 - Loss:  7646.8867 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  95 - Loss:  8088.3174 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  96 - Loss:  7148.5259 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  97 - Loss:  7045.5684 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  98 - Loss:  6476.0635 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch  99 - Loss:  6891.5166 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch 100 - Loss:  5696.5957 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch 101 - Loss:  6480.2598 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch 102 - Loss:  6083.7490 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch 103 - Loss:  5785.5132 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch 104 - Loss:  6349.4106 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch 105 - Loss:  5478.8447 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch 106 - Loss:  8297.0547 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch 107 - Loss:  5044.4609 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch 108 - Loss:  5323.8496 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch 109 - Loss:  5903.0283 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch 110 - Loss:  5023.2432 Validation Accuracy: 0.500000\n",
      "Epoch  1, Batch 111 - Loss:  5496.5537 Validation Accuracy: 0.515625\n",
      "Epoch  1, Batch 112 - Loss:  4644.7603 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch 113 - Loss:  6906.3096 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch 114 - Loss:  5315.6865 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch 115 - Loss:  5573.1338 Validation Accuracy: 0.503906\n",
      "Epoch  1, Batch 116 - Loss:  5549.8818 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 117 - Loss:  4331.3994 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 118 - Loss:  5822.3525 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch 119 - Loss:  6590.1445 Validation Accuracy: 0.515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 120 - Loss:  5607.7095 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 121 - Loss:  5241.8135 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch 122 - Loss:  5874.7222 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 123 - Loss:  3950.5862 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 124 - Loss:  4063.6938 Validation Accuracy: 0.531250\n",
      "Epoch  1, Batch 125 - Loss:  4261.7324 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 126 - Loss:  6927.7158 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 127 - Loss:  4936.6602 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 128 - Loss:  5399.1934 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 129 - Loss:  5193.9814 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 130 - Loss:  4808.8882 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 131 - Loss:  3975.6162 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 132 - Loss:  3755.2871 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 133 - Loss:  4802.3921 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 134 - Loss:  3773.2861 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 135 - Loss:  3679.9905 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 136 - Loss:  3499.2527 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 137 - Loss:  3961.6733 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 138 - Loss:  4136.5010 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 139 - Loss:  3757.4897 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 140 - Loss:  3301.9912 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 141 - Loss:  4374.0439 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 142 - Loss:  3157.2329 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 143 - Loss:  4548.5840 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 144 - Loss:  4911.0850 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 145 - Loss:  2842.2983 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 146 - Loss:  5396.3691 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 147 - Loss:  4046.9314 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 148 - Loss:  3072.2463 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 149 - Loss:  2722.7163 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 150 - Loss:  3334.9529 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 151 - Loss:  3876.6667 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 152 - Loss:  4264.1553 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 153 - Loss:  4127.4858 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 154 - Loss:  4379.0229 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 155 - Loss:  5053.0571 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 156 - Loss:  4903.2188 Validation Accuracy: 0.597656\n",
      "Epoch  1, Batch 157 - Loss:  3535.0166 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 158 - Loss:  3679.8928 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 159 - Loss:  3653.4526 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 160 - Loss:  3155.8262 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 161 - Loss:  4180.3677 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 162 - Loss:  3513.7258 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 163 - Loss:  4024.8564 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 164 - Loss:  4857.4697 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 165 - Loss:  4592.0674 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 166 - Loss:  4047.2324 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 167 - Loss:  3517.6255 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 168 - Loss:  2750.3696 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 169 - Loss:  3958.3237 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 170 - Loss:  4900.4492 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 171 - Loss:  3461.4814 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 172 - Loss:  3837.4099 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 173 - Loss:  3767.1143 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 174 - Loss:  4730.6680 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 175 - Loss:  3510.6143 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 176 - Loss:  3861.3936 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 177 - Loss:  3712.4006 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 178 - Loss:  3563.6997 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 179 - Loss:  4188.7510 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 180 - Loss:  3200.6619 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 181 - Loss:  3510.3960 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 182 - Loss:  2455.1221 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 183 - Loss:  3874.8994 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 184 - Loss:  2744.6152 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 185 - Loss:  3691.2017 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 186 - Loss:  3450.3347 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 187 - Loss:  3374.0066 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 188 - Loss:  3543.1541 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 189 - Loss:  3014.3464 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 190 - Loss:  3314.4492 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 191 - Loss:  3320.6045 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 192 - Loss:  3145.8281 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 193 - Loss:  2775.8140 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 194 - Loss:  3197.0571 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 195 - Loss:  3384.5916 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 196 - Loss:  3171.6082 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 197 - Loss:  3033.5129 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 198 - Loss:  3516.4727 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 199 - Loss:  4594.8638 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 200 - Loss:  3663.5884 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 201 - Loss:  2834.4629 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 202 - Loss:  2089.2876 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 203 - Loss:  4422.8936 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 204 - Loss:  3062.5249 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 205 - Loss:  2160.9597 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 206 - Loss:  2870.0854 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 207 - Loss:  2964.9739 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 208 - Loss:  3043.7698 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 209 - Loss:  3867.3926 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 210 - Loss:  3310.8848 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 211 - Loss:  3486.6255 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 212 - Loss:  3309.8433 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 213 - Loss:  3236.1333 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 214 - Loss:  3289.0215 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 215 - Loss:  2391.5510 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 216 - Loss:  2907.4680 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 217 - Loss:  3838.2817 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 218 - Loss:  2142.0342 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 219 - Loss:  3204.3701 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 220 - Loss:  3011.2559 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 221 - Loss:  3004.9983 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 222 - Loss:  2471.6777 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 223 - Loss:  2934.8401 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 224 - Loss:  3036.0547 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 225 - Loss:  3288.8232 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 226 - Loss:  3611.0718 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 227 - Loss:  3516.8738 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 228 - Loss:  3383.8081 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 229 - Loss:  3494.6436 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 230 - Loss:  4912.6118 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 231 - Loss:  2690.9746 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 232 - Loss:  3000.7578 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 233 - Loss:  3141.8647 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 234 - Loss:  3694.5405 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 235 - Loss:  1847.8923 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 236 - Loss:  2604.2004 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 237 - Loss:  2344.7356 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 238 - Loss:  2936.1143 Validation Accuracy: 0.695312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 239 - Loss:  2561.1453 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 240 - Loss:  2056.4453 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 241 - Loss:  2978.0989 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 242 - Loss:  2729.9756 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 243 - Loss:  2413.9639 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 244 - Loss:  3460.8796 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 245 - Loss:  2772.0190 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 246 - Loss:  2143.0825 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 247 - Loss:  2889.6252 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 248 - Loss:  3234.0430 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 249 - Loss:  3611.5098 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 250 - Loss:  3124.0039 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 251 - Loss:  2845.3840 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 252 - Loss:  2410.2854 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 253 - Loss:  3488.5742 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 254 - Loss:  2687.2920 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 255 - Loss:  2117.7607 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 256 - Loss:  2046.6678 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 257 - Loss:  2639.7861 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 258 - Loss:  3121.4434 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 259 - Loss:  2840.4763 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 260 - Loss:  2434.5627 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 261 - Loss:  2561.1304 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 262 - Loss:  1694.8154 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 263 - Loss:  2830.7979 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 264 - Loss:  3043.2046 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 265 - Loss:  1638.1840 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 266 - Loss:  3216.1633 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 267 - Loss:  2414.3091 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 268 - Loss:  3327.1155 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 269 - Loss:  3388.5042 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 270 - Loss:  2871.2651 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 271 - Loss:  3244.8652 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 272 - Loss:  2703.0305 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 273 - Loss:  2565.3013 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 274 - Loss:  3167.8682 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 275 - Loss:  2423.4277 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 276 - Loss:  2796.4194 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 277 - Loss:  2201.4365 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 278 - Loss:  2210.9299 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 279 - Loss:  2260.1335 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 280 - Loss:  2172.7080 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 281 - Loss:  2287.4468 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 282 - Loss:  2149.9390 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 283 - Loss:  2945.1604 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 284 - Loss:  2371.2458 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 285 - Loss:  1781.2097 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 286 - Loss:  3085.3652 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 287 - Loss:  1998.7257 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 288 - Loss:  2690.7178 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 289 - Loss:  2288.0591 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 290 - Loss:  2518.5859 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 291 - Loss:  2049.7910 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 292 - Loss:  2289.8418 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 293 - Loss:  2469.0156 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 294 - Loss:  2536.7441 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 295 - Loss:  3389.2400 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 296 - Loss:  2374.2244 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 297 - Loss:  1852.3469 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 298 - Loss:  3046.2627 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 299 - Loss:  2444.0635 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 300 - Loss:  1709.1440 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 301 - Loss:  1996.6283 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 302 - Loss:  2009.3719 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 303 - Loss:  2176.8398 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 304 - Loss:  2095.3359 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 305 - Loss:  2184.7932 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 306 - Loss:  1850.7986 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 307 - Loss:  2768.5269 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 308 - Loss:  2813.8386 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 309 - Loss:  2330.0244 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 310 - Loss:  1590.3025 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 311 - Loss:  2031.8281 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 312 - Loss:  2244.0933 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 313 - Loss:  1065.3840 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 314 - Loss:  2082.9658 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 315 - Loss:  2921.9751 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 316 - Loss:  2018.7867 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 317 - Loss:  2209.1606 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 318 - Loss:  1545.8540 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 319 - Loss:  1993.0671 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 320 - Loss:  2546.1821 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 321 - Loss:  2671.7285 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 322 - Loss:  1662.8286 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 323 - Loss:  1629.4597 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 324 - Loss:  1412.5563 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 325 - Loss:  2832.9189 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 326 - Loss:  1126.5740 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 327 - Loss:  1334.4619 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 328 - Loss:  1726.0682 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 329 - Loss:  1604.5642 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 330 - Loss:  2175.6169 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 331 - Loss:  2138.1797 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 332 - Loss:  1918.5042 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 333 - Loss:  1596.0984 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 334 - Loss:  2142.1953 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 335 - Loss:  1761.3298 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 336 - Loss:  1873.3622 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 337 - Loss:  1256.3625 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 338 - Loss:  2499.3223 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 339 - Loss:  1825.1831 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 340 - Loss:  2576.3013 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 341 - Loss:  2202.9558 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 342 - Loss:  1710.9569 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 343 - Loss:  2817.6670 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 344 - Loss:  1652.7480 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 345 - Loss:  2321.0884 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 346 - Loss:  1700.5425 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 347 - Loss:  2300.7051 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 348 - Loss:  2122.2212 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 349 - Loss:  2046.8196 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 350 - Loss:  2339.8789 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 351 - Loss:  1699.2815 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 352 - Loss:  2219.2117 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 353 - Loss:   999.6949 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 354 - Loss:  2429.9292 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 355 - Loss:  2000.8663 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 356 - Loss:  1727.0427 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 357 - Loss:  2721.6392 Validation Accuracy: 0.757812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 358 - Loss:  1488.1646 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 359 - Loss:  1560.4800 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 360 - Loss:  1850.6295 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 361 - Loss:  2452.7612 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 362 - Loss:  2030.1956 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 363 - Loss:   858.8138 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 364 - Loss:  2053.7412 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 365 - Loss:  1883.9835 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 366 - Loss:  2622.8201 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 367 - Loss:  2799.4607 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 368 - Loss:  2474.0732 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 369 - Loss:  1493.6174 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 370 - Loss:  2531.9136 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 371 - Loss:  1869.0336 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 372 - Loss:  2738.9839 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 373 - Loss:   925.8134 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 374 - Loss:  1684.1755 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 375 - Loss:  1325.0234 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 376 - Loss:  1775.6888 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 377 - Loss:  1638.0281 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 378 - Loss:  1869.7761 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 379 - Loss:  2341.4722 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 380 - Loss:  3362.3528 Validation Accuracy: 0.761719\n",
      "Epoch  1, Batch 381 - Loss:  2187.0415 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 382 - Loss:  2003.2430 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 383 - Loss:  1543.7203 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 384 - Loss:  1521.3108 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 385 - Loss:  1720.0171 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 386 - Loss:  2304.7988 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 387 - Loss:  2415.9395 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 388 - Loss:  1350.3416 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 389 - Loss:  1581.1757 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 390 - Loss:  1562.6653 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 391 - Loss:  2134.5283 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 392 - Loss:  2175.4707 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 393 - Loss:  1516.7349 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 394 - Loss:  2237.0435 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 395 - Loss:  1579.0380 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 396 - Loss:  2319.2346 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 397 - Loss:  1949.1558 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 398 - Loss:  2453.7500 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 399 - Loss:  2073.7683 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 400 - Loss:  2461.8120 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 401 - Loss:  1763.2131 Validation Accuracy: 0.765625\n",
      "Epoch  1, Batch 402 - Loss:  1986.6875 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 403 - Loss:  1785.4006 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 404 - Loss:   900.4463 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 405 - Loss:  1351.2070 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 406 - Loss:  2004.2859 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 407 - Loss:  1252.6450 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 408 - Loss:  1534.6162 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 409 - Loss:  1953.7311 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 410 - Loss:  1758.3815 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 411 - Loss:  1039.5375 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 412 - Loss:  2113.9402 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 413 - Loss:  1997.4429 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 414 - Loss:  2291.2637 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 415 - Loss:  2268.7739 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 416 - Loss:  1819.3099 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 417 - Loss:  1560.7825 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 418 - Loss:  1761.6315 Validation Accuracy: 0.785156\n",
      "Epoch  1, Batch 419 - Loss:  1173.0398 Validation Accuracy: 0.789062\n",
      "Epoch  1, Batch 420 - Loss:  1656.3379 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 421 - Loss:  1872.0173 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 422 - Loss:  1391.9326 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 423 - Loss:  1539.6742 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 424 - Loss:  1929.3777 Validation Accuracy: 0.781250\n",
      "Epoch  1, Batch 425 - Loss:  1946.5801 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 426 - Loss:  1532.6606 Validation Accuracy: 0.773438\n",
      "Epoch  1, Batch 427 - Loss:  1734.8383 Validation Accuracy: 0.777344\n",
      "Epoch  1, Batch 428 - Loss:  1889.4989 Validation Accuracy: 0.769531\n",
      "Epoch  1, Batch 429 - Loss:  2116.0605 Validation Accuracy: 0.777344\n",
      "Testing Accuracy: 0.70703125\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={x: batch_x, y: batch_y, keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y, keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} - Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "            \n",
    "            \n",
    "     # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "            x: mnist.test.images[:test_valid_size],\n",
    "            y: mnist.test.labels[:test_valid_size],\n",
    "            keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
